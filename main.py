import datetime
import json 

import streamlit as st
from st_click_detector import click_detector
from annotated_text import annotated_text

import nltk
from nltk.tokenize import sent_tokenize
from nltk.corpus import stopwords

from difflib import SequenceMatcher

try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

all_stopwords = set(stopwords.words('english'))


def loralay_eval_interface(gold_samples, bigbird_samples):
    st.title("LoRaLay Evaluation Interface")

    doc_id = st.selectbox(
        'Choose a file',
        set([sample_id for sample_id, _ in gold_samples.items()]),
    )

    placeholder_gold = st.empty()
    placeholder_bigbird = st.empty()

    with placeholder_gold.container():
        st.header("Ground-truth abstract")
        st.write(gold_samples[doc_id])

    with placeholder_bigbird.container():
        st.header("Summary generated by BigBird-Pegasus")
        st.caption("Click on any sentence to highlight the corresponding words in the ground-truth abstract.")

        content = ""
        for sent_idx, sent in enumerate(bigbird_samples[doc_id]):
            content += f"<p><a href='#' id='bigbird_{doc_id}_sent_{sent_idx}' style='color:black;'>{bigbird_samples[doc_id][sent_idx]}</a></p>"

    clicked = click_detector(content)

    for sent_idx in range(len(bigbird_samples[doc_id])):
        if clicked == f"bigbird_{doc_id}_sent_{sent_idx}":
            words_in_sent = bigbird_samples[doc_id][sent_idx].lower().split()
            gold_summary = gold_samples[doc_id] 
            gold_words = gold_summary.split()
            annotated_gold_sent = []
            for w in gold_words:
                if w.lower() not in all_stopwords:
                    if w.lower() in words_in_sent:
                    # if w.lower() in words_in_sent and w.lower() not in all_stopwords:
                        annotated_gold_sent.append((w + " ", ""))
                    else:
                        is_matched = False 
                        for w_sent in words_in_sent:
                            if SequenceMatcher(a=w.lower(), b=w_sent).ratio() > 0.8:
                                is_matched = True 
                        if is_matched:
                            annotated_gold_sent.append((w + " ", ""))
                        else:
                            annotated_gold_sent.append(w + " ")    
                else:
                    annotated_gold_sent.append(w + " ")    

            with placeholder_gold.container():
                st.header("Abstract")
                annotated_text(*annotated_gold_sent)

    st.caption("Use the sliders below to evaluate the generated summary.")
    placeholder_bigbird_sliders = st.empty()
    

    def update_slider_coh():
        with open(f"./slider_outputs/bigbird_{doc_id}_coh", 'a') as fw:
            fw.write(str(st.session_state[f'bigbird_{doc_id}_coh']) + "\n")

    def update_slider_con():
        with open(f"./slider_outputs/bigbird_{doc_id}_con", 'a') as fw:
            fw.write(str(st.session_state[f'bigbird_{doc_id}_con']) + "\n")

    def update_slider_flu():
        with open(f"./slider_outputs/bigbird_{doc_id}_flu", 'a') as fw:
            fw.write(str(st.session_state[f'bigbird_{doc_id}_flu']) + "\n")

    def update_slider_rel():
        with open(f"./slider_outputs/bigbird_{doc_id}_rel", 'a') as fw:
            fw.write(str(st.session_state[f'bigbird_{doc_id}_rel']) + "\n")


    with placeholder_bigbird_sliders.container():
        coherence = st.slider('Coherence', 0., 5., 2.5, 0.1, key=f'bigbird_{doc_id}_coh', on_change=update_slider_coh)
        consistency = st.slider('Consistency', 0., 5., 2.5, 0.1, key=f'bigbird_{doc_id}_con', on_change=update_slider_con)
        fluency = st.slider('Fluency', 0., 5., 2.5, 0.1, key=f'bigbird_{doc_id}_flu', on_change=update_slider_flu)
        relevance = st.slider('Relevance', 0., 5., 2.5, 0.1, key=f'bigbird_{doc_id}_rel', on_change=update_slider_rel)


if __name__ == "__main__":

    with open("samples/gold.txt") as f:
        gold_samples = f.readlines()
    with open("samples/bigbird-pegasus.txt") as f:
        bigbird_samples = f.readlines()

    gold_samples = [json.loads(sample) for sample in gold_samples]
    gold_samples = {sample["id"]: sample["abstract"] for sample in gold_samples}
    bigbird_samples = [json.loads(sample) for sample in bigbird_samples]
    bigbird_samples = {sample["id"]: sent_tokenize(sample["output"]) for sample in bigbird_samples}


    loralay_eval_interface(gold_samples, bigbird_samples)
