import argparse
import datetime
import json
import os
import shutil 
from components import init_components, st_highlightable_text
import streamlit as st
from st_click_detector import click_detector
from annotated_text import annotated_text

import nltk
from nltk.tokenize import sent_tokenize
from nltk.corpus import stopwords

from difflib import SequenceMatcher

try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

EN_STOPWORDS = set(stopwords.words('english'))
FR_STOPWORDS = set(stopwords.words('french'))
SLIDER_STEP=1.
SLIDER_DEFAULT_VAL=0.
SLIDER_MIN_VAL, SLIDER_MAX_VAL = 0., 5.
PREC_VALUES=(0, 25, 50, 75, 100)
REC_VALUES=(0, 25, 50, 75, 100)


def _highlight_in_gold_sample(sent, gold_summary, stopwords):
    words_in_sent = sent.lower().split()
    gold_words = gold_summary.split()
    annotated_gold_summ = []
    for w in gold_words:
        if w.lower() not in stopwords:
            if w.lower() in words_in_sent:
                annotated_gold_summ.append((w + " ", ""))
            else:
                is_matched = False 
                for w_sent in words_in_sent:
                    if SequenceMatcher(a=w.lower(), b=w_sent).ratio() > 0.8:
                        is_matched = True 
                if is_matched:
                    annotated_gold_summ.append((w + " ", ""))
                else:
                    annotated_gold_summ.append(w + " ")    
        else:
            annotated_gold_summ.append(w + " ") 
    return annotated_gold_summ


def _create_sliders(model_name, doc_id, results_dir):
    def update_slider_coh():
        st.session_state[f'{model_name}_{doc_id}_coh_updated'] = st.session_state[f'{model_name}_{doc_id}_coh'] 
        with open(os.path.join(results_dir, f"{model_name}_{doc_id}_coh"), 'a') as fw:
            fw.write(str(st.session_state[f'{model_name}_{doc_id}_coh']) + "\n")

    def update_slider_con():
        st.session_state[f'{model_name}_{doc_id}_con_updated'] = st.session_state[f'{model_name}_{doc_id}_con'] 
        with open(os.path.join(results_dir, f"{model_name}_{doc_id}_con"), 'a') as fw:
            fw.write(str(st.session_state[f'{model_name}_{doc_id}_con']) + "\n")

    def update_slider_flu():
        st.session_state[f'{model_name}_{doc_id}_flu_updated'] = st.session_state[f'{model_name}_{doc_id}_flu'] 
        with open(os.path.join(results_dir, f"{model_name}_{doc_id}_flu"), 'a') as fw:
            fw.write(str(st.session_state[f'{model_name}_{doc_id}_flu']) + "\n")

    def update_slider_rel():
        print("updating")
        st.session_state[f'{model_name}_{doc_id}_rel_updated'] = st.session_state[f'{model_name}_{doc_id}_rel'] 
        with open(os.path.join(results_dir, f"{model_name}_{doc_id}_rel"), 'a') as fw:
            print("here")
            fw.write(str(st.session_state[f'{model_name}_{doc_id}_rel']) + "\n")

    st.slider(
        'Coherence', 
        SLIDER_MIN_VAL, 
        SLIDER_MAX_VAL, 
        SLIDER_DEFAULT_VAL if f"{model_name}_{doc_id}_coh_updated" not in st.session_state else st.session_state[f'{model_name}_{doc_id}_coh_updated'],
        SLIDER_STEP, 
        key=f'{model_name}_{doc_id}_coh', 
        on_change=update_slider_coh
    )
    st.slider(
        'Consistency', SLIDER_MIN_VAL, 
        SLIDER_MAX_VAL, 
        SLIDER_DEFAULT_VAL if f"{model_name}_{doc_id}_con_updated" not in st.session_state else st.session_state[f'{model_name}_{doc_id}_con_updated'],
        SLIDER_STEP, 
        key=f'{model_name}_{doc_id}_con', 
        on_change=update_slider_con
    )
    st.slider(
        'Fluency', SLIDER_MIN_VAL, 
        SLIDER_MAX_VAL, 
        SLIDER_DEFAULT_VAL if f"{model_name}_{doc_id}_flu_updated" not in st.session_state else st.session_state[f'{model_name}_{doc_id}_flu_updated'],
        SLIDER_STEP,  
        key=f'{model_name}_{doc_id}_flu', 
        on_change=update_slider_flu
    )
    st.slider(
        'Relevance', SLIDER_MIN_VAL, 
        SLIDER_MAX_VAL, 
        SLIDER_DEFAULT_VAL if f"{model_name}_{doc_id}_rel_updated" not in st.session_state else st.session_state[f'{model_name}_{doc_id}_rel_updated'], 
        SLIDER_STEP,  
        key=f'{model_name}_{doc_id}_rel', 
        on_change=update_slider_rel
    )


def _display_placeholder_model(
    model_name, 
    gen_samples, 
    doc_id, 
    bigbird_n_sent, 
    layout_bigbird_n_sent,
    prec_results_dir,
    rec_results_dir,
):
    if model_name == "bigbird":
        # st.subheader("Summary generated by BigBird")
        st.subheader("Summary generated by model A")
    else:
        # st.subheader("Summary generated by BigBird+Layout")
        st.subheader("Summary generated by model B")
    st.info("Summary is split by sentence. Click on any sentence to highlight the corresponding words in the ground-truth abstract. Set precision and recall %.")
    
    def _update_gen_checkbox(sent_idx):
        for i in range(bigbird_n_sent):
            if model_name != "bigbird" or i != sent_idx:
                st.session_state[f"chk_bigbird_{doc_id}_{i}"] = False
        for i in range(layout_bigbird_n_sent):
            if model_name != "layout_bigbird" or i != sent_idx:
                st.session_state[f"chk_layout_bigbird_{doc_id}_{i}"] = False

    def _update_prec_eval(sent_idx):
        if f"{model_name}_{doc_id}_sent{sent_idx}_prec_updated" not in st.session_state:
            st.session_state[f'{model_name}_{doc_id}_sent{sent_idx}_prec_updated'] = st.session_state[f'{model_name}_{doc_id}_sent{sent_idx}_prec'] 
        st.session_state[f'{model_name}_{doc_id}_sent{sent_idx}_prec_updated'] = st.session_state[f'{model_name}_{doc_id}_sent{sent_idx}_prec'] 
        with open(os.path.join(prec_results_dir, f"{model_name}_{doc_id}_sent{sent_idx}_prec"), 'a') as fw:
            fw.write(str(st.session_state[f'{model_name}_{doc_id}_sent{sent_idx}_prec']) + "\n")

    for sent_idx, sent in enumerate(gen_samples[doc_id]):
        first_col, second_col, third_col = st.columns([1, 5, 5])
        with first_col:
            if sent_idx == 0:
                st.markdown("\n")
                st.markdown("\n")
            st.checkbox("", key=f'chk_{model_name}_{doc_id}_{sent_idx}', on_change=_update_gen_checkbox, args=(sent_idx,))
        with second_col:
            if sent_idx == 0:
                st.markdown("**Sentence**")
            st.markdown(sent)
        with third_col:
            st.radio(
                "Precision %", 
                PREC_VALUES, 
                key=f'{model_name}_{doc_id}_sent{sent_idx}_prec', 
                on_change=_update_prec_eval, 
                args=(sent_idx,),
                index=PREC_VALUES[0] if f'{model_name}_{doc_id}_sent{sent_idx}_prec_updated' not in st.session_state else PREC_VALUES.index(st.session_state[f'{model_name}_{doc_id}_sent{sent_idx}_prec_updated']),
                label_visibility="visible" if sent_idx == 0 else "collapsed",
                horizontal=True,
            )
        # with fourth_col:
        #     st.selectbox(
        #         "Recall %", 
        #         REC_VALUES, 
        #         key=f'{model_name}_{doc_id}_sent{sent_idx}_rec', 
        #         on_change=_update_rec_eval, 
        #         args=(sent_idx, model_name, rec_results_dir),
        #         index=REC_VALUES[0] if f'{model_name}_{doc_id}_sent{sent_idx}_rec_updated' not in st.session_state else REC_VALUES.index(st.session_state[f'{model_name}_{doc_id}_sent{sent_idx}_rec_updated']),
        #         label_visibility="visible" if sent_idx == 0 else "collapsed",
        #     )

    def _update_rec_eval():
        if f"{model_name}_{doc_id}_rec_updated" not in st.session_state:
            st.session_state[f'{model_name}_{doc_id}_rec_updated'] = st.session_state[f'{model_name}_{doc_id}_rec'] 
        st.session_state[f'{model_name}_{doc_id}_rec_updated'] = st.session_state[f'{model_name}_{doc_id}_rec'] 
        with open(os.path.join(rec_results_dir, f"{model_name}_{doc_id}_rec"), 'a') as fw:
            fw.write(str(st.session_state[f'{model_name}_{doc_id}_rec']) + "\n")

    st.radio(
        "Recall %",
        REC_VALUES,
        key=f'{model_name}_{doc_id}_rec',
        on_change=_update_rec_eval, 
        index=REC_VALUES[0] if f'{model_name}_{doc_id}_rec_updated' not in st.session_state else REC_VALUES.index(st.session_state[f'{model_name}_{doc_id}_rec_updated']),
        horizontal=True,
    ) 

def load_results_in_session_state(slider_results_dir, prec_results_dir, rec_results_dir):
    slider_results_files = os.listdir(slider_results_dir)
    prec_results_files = os.listdir(prec_results_dir)
    rec_results_files = os.listdir(rec_results_dir)

    for filename in slider_results_files:
        model_name, doc_id, cat = filename.split("_")
        with open(os.path.join(slider_results_dir, filename), 'r') as f:
            lines = f.readlines()
        last_result = float(lines[-1])
        st.session_state[f'{model_name}_{doc_id}_{cat}_updated'] = last_result

    for filename in prec_results_files:
        model_name, doc_id, sent_idx, _ = filename.split("_")
        with open(os.path.join(prec_results_dir, filename), 'r') as f:
            lines = f.readlines()
        last_result = float(lines[-1])
        st.session_state[f'{model_name}_{doc_id}_{sent_idx}_prec_updated'] = last_result

    for filename in rec_results_files:
        model_name, doc_id, _ = filename.split("_")
        with open(os.path.join(rec_results_dir, filename), 'r') as f:
            lines = f.readlines()
        last_result = float(lines[-1])
        st.session_state[f'{model_name}_{doc_id}_rec_updated'] = last_result



def loralay_eval_interface(
    gold_samples, 
    bigbird_samples, 
    layout_bigbird_samples, 
    doc_id, 
    all_doc_ids,
    samples_lang,
    slider_results_dir,
    prec_results_dir,
    rec_results_dir,
):
    st.title("LoRaLay Evaluation Interface")

    load_results_in_session_state(slider_results_dir, prec_results_dir, rec_results_dir)

    # all_doc_ids = tuple([sample_id for sample_id, _ in gold_samples.items()])
    # all_doc_ids = sorted(all_doc_ids)
    last_idx = len(all_doc_ids) - 1

    if "doc_idx" not in st.session_state:
        st.session_state.doc_idx = all_doc_ids.index(doc_id)
    else:
        doc_id = all_doc_ids[st.session_state.doc_idx]
        with open("./last_doc_id.txt", 'w') as fw:
            fw.write(doc_id)

    st.header(f"Document {doc_id} ({st.session_state.doc_idx + 1}/{len(all_doc_ids)})")        
        
    placeholder_gold = st.empty()
    placeholder_bigbird, placeholder_layout_bigbird = st.tabs(["Model A", "Model B"])

    with placeholder_gold.container():
        st.subheader("Ground-truth abstract")
        st.write(gold_samples[doc_id])
        text = gold_samples[doc_id].split()

        highlighted = st_highlightable_text(text, [ix < 10 for ix in range(len(text))], ["consider", "coupled", "gravity"], key="gold-abstract")
        print("Highlighted words", highlighted)


    bigbird_n_sent = len(bigbird_samples[doc_id])
    layout_bigbird_n_sent = len(layout_bigbird_samples[doc_id])

    with placeholder_bigbird.container():
        _display_placeholder_model(
            "bigbird", 
            bigbird_samples, 
            doc_id, 
            bigbird_n_sent, 
            layout_bigbird_n_sent,
            prec_results_dir,
            rec_results_dir,
        )
        st.info("Use the sliders below to evaluate the generated summary.")
        _create_sliders("bigbird", doc_id, slider_results_dir)

    if samples_lang[doc_id] == "en":
        stopwords = EN_STOPWORDS
    else:
        assert samples_lang[doc_id] == "fr"
        stopwords = FR_STOPWORDS

    for sent_idx in range(bigbird_n_sent):
        if st.session_state[f'chk_bigbird_{doc_id}_{sent_idx}']:
            annotated_gold_summ = _highlight_in_gold_sample(
                bigbird_samples[doc_id][sent_idx],
                gold_samples[doc_id],
                stopwords
            )
            with placeholder_gold.container():
                st.subheader("Abstract")
                annotated_text(*annotated_gold_summ)
    

    with placeholder_layout_bigbird.container():
        _display_placeholder_model(
            "layout_bigbird", 
            layout_bigbird_samples, 
            doc_id, 
            bigbird_n_sent, 
            layout_bigbird_n_sent,
            prec_results_dir,
            rec_results_dir
        )
        st.info("Use the sliders below to evaluate the generated summary.")
        _create_sliders("layout_bigbird", doc_id, slider_results_dir)

                
    for sent_idx in range(layout_bigbird_n_sent):
        if st.session_state[f'chk_layout_bigbird_{doc_id}_{sent_idx}']:
            annotated_gold_summ = _highlight_in_gold_sample(
                layout_bigbird_samples[doc_id][sent_idx],
                gold_samples[doc_id],
                stopwords
            )
            with placeholder_gold.container():
                st.subheader("Abstract")
                annotated_text(*annotated_gold_summ)


    def go_to_next():
        st.session_state.doc_idx += 1
    def go_to_previous():
        st.session_state.doc_idx -= 1

    left, _, right = st.columns([1, 8, 1])
    with left:
        if st.session_state.doc_idx > 0:
            st.button('Previous', on_click=go_to_previous)
    with right:
        if st.session_state.doc_idx < last_idx:
            st.button('Next', on_click=go_to_next)
        

def load_samples(samples, is_gold=False):
    samples = [json.loads(sample) for sample in samples]
    if is_gold:
        samples_lang = {
            sample["id"]: sample["lang"] for sample in samples
        }
    else:
        samples_lang = None
    samples = {
        sample["id"]: sample["abstract"] if is_gold else sent_tokenize(sample["output"]) for sample in samples
    }
    return samples, samples_lang


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    
    parser.add_argument(
        "--path_to_gold",
        type=str,
        default="samples/gold.txt",
    )
    parser.add_argument(
        "--path_to_bigbird",
        type=str,
        default="samples/bigbird.txt",
    )
    parser.add_argument(
        "--path_to_layout_bigbird",
        type=str,
        default="samples/layout-bigbird.txt",
    )
    parser.add_argument(
        "--results_dir",
        type=str,
        default="eval_results",
    )
    parser.add_argument(
        "--overwrite_eval",
        action="store_true", 
    )
    parser.add_argument(
        "--dev",
        action="store_true", 
        help="Runs in development mode (frontend)"
    )
    args = parser.parse_args()


    init_components(args.dev)

    with open(args.path_to_gold) as f:
        gold_samples = f.readlines()
    with open(args.path_to_bigbird) as f:
        bigbird_samples = f.readlines()
    with open(args.path_to_layout_bigbird) as f:
        layout_bigbird_samples = f.readlines()

    gold_samples, samples_lang = load_samples(gold_samples, is_gold=True)
    bigbird_samples, _ = load_samples(bigbird_samples)
    layout_bigbird_samples, _ = load_samples(layout_bigbird_samples)

    all_doc_ids = tuple([sample_id for sample_id, _ in gold_samples.items()])
    # all_doc_ids = sorted(all_doc_ids)

    slider_results_dir = os.path.join(args.results_dir, "slider_outputs")
    prec_results_dir = os.path.join(args.results_dir, "precision_outputs")
    rec_results_dir = os.path.join(args.results_dir, "recall_outputs")

    @st.cache
    def prepare_results_dir():
        if os.path.isdir(args.results_dir):
            if args.overwrite_eval:
                if  (
                    (
                        os.path.isdir(slider_results_dir) and len(os.listdir(slider_results_dir)) > 0 
                    ) or 
                    (
                        os.path.isdir(prec_results_dir) and len(os.listdir(prec_results_dir)) > 0
                    ) 
                    or 
                    (
                        os.path.isdir(rec_results_dir) and len(os.listdir(rec_results_dir)) > 0
                    ) 
                ):
                    if len(os.listdir(slider_results_dir)) > 0:
                        shutil.rmtree(slider_results_dir)
                    if len(os.listdir(prec_results_dir)) > 0:
                        shutil.rmtree(prec_results_dir)
                    if len(os.listdir(rec_results_dir)) > 0:
                        shutil.rmtree(rec_results_dir)
                
                    os.makedirs(slider_results_dir)
                    os.makedirs(prec_results_dir)
                    os.makedirs(rec_results_dir)
                if os.path.isfile("./last_doc_id.txt"):
                    os.remove("./last_doc_id.txt")
            else:
                if not os.path.isdir(slider_results_dir):
                    os.makedirs(slider_results_dir)
                if not os.path.isdir(prec_results_dir):
                    os.makedirs(prec_results_dir)
                if not os.path.isdir(rec_results_dir):
                    os.makedirs(rec_results_dir)
        else:
            os.mkdir(args.results_dir)
            os.makedirs(slider_results_dir)
            os.makedirs(prec_results_dir)
            os.makedirs(rec_results_dir)
    
    prepare_results_dir()

    if os.path.isfile("./last_doc_id.txt"):
        with open("./last_doc_id.txt", 'r') as f:
            doc_id = f.read().strip()
    else:
        doc_id = all_doc_ids[0]

    loralay_eval_interface(
        gold_samples, 
        bigbird_samples, 
        layout_bigbird_samples, 
        doc_id, 
        all_doc_ids,
        samples_lang,
        slider_results_dir,
        prec_results_dir,
        rec_results_dir,
    )
