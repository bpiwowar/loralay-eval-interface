import argparse
import datetime
import json
import os
import random
import shutil 

import streamlit as st
from st_click_detector import click_detector
from annotated_text import annotated_text

import nltk
from nltk.tokenize import sent_tokenize
from nltk.corpus import stopwords

from difflib import SequenceMatcher

try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

EN_STOPWORDS = set(stopwords.words('english'))
FR_STOPWORDS = set(stopwords.words('french'))
CCFR_DEFAULT_VAL = -1
PREC_REC_DEFAULT_VAL = -1
CCFR_VALUES = (CCFR_DEFAULT_VAL, 0, 1, 2, 3, 4, 5)
PREC_VALUES = (PREC_REC_DEFAULT_VAL, 0, 25, 50, 75, 100)
REC_VALUES = (PREC_REC_DEFAULT_VAL, 0, 25, 50, 75, 100)


def _highlight_in_gold_sample(sent, gold_summary, stopwords):
    words_in_sent = sent.lower().split()
    gold_words = gold_summary.split()
    annotated_gold_summ = []
    for w in gold_words:
        if w.lower() not in stopwords:
            if w.lower() in words_in_sent:
                annotated_gold_summ.append((w + " ", ""))
            else:
                is_matched = False 
                for w_sent in words_in_sent:
                    if SequenceMatcher(a=w.lower(), b=w_sent).ratio() > 0.8:
                        is_matched = True 
                if is_matched:
                    annotated_gold_summ.append((w + " ", ""))
                else:
                    annotated_gold_summ.append(w + " ")    
        else:
            annotated_gold_summ.append(w + " ") 
    return annotated_gold_summ


def _create_radios(model_name, doc_id, results_dir):
    def update_radio_coh():
        st.session_state[f'{model_name}_{doc_id}_coh_updated'] = st.session_state[f'{model_name}_{doc_id}_coh'] 
        with open(os.path.join(results_dir, f"{model_name}_{doc_id}_coh"), 'a') as fw:
            fw.write(str(st.session_state[f'{model_name}_{doc_id}_coh']) + "\n")

    def update_radio_con():
        st.session_state[f'{model_name}_{doc_id}_con_updated'] = st.session_state[f'{model_name}_{doc_id}_con'] 
        with open(os.path.join(results_dir, f"{model_name}_{doc_id}_con"), 'a') as fw:
            fw.write(str(st.session_state[f'{model_name}_{doc_id}_con']) + "\n")

    def update_radio_flu():
        st.session_state[f'{model_name}_{doc_id}_flu_updated'] = st.session_state[f'{model_name}_{doc_id}_flu'] 
        with open(os.path.join(results_dir, f"{model_name}_{doc_id}_flu"), 'a') as fw:
            fw.write(str(st.session_state[f'{model_name}_{doc_id}_flu']) + "\n")

    def update_radio_rel():
        st.session_state[f'{model_name}_{doc_id}_rel_updated'] = st.session_state[f'{model_name}_{doc_id}_rel'] 
        with open(os.path.join(results_dir, f"{model_name}_{doc_id}_rel"), 'a') as fw:
            fw.write(str(st.session_state[f'{model_name}_{doc_id}_rel']) + "\n")

    _, center, _ = st.columns([3, 8, 1])

    with center:
        st.radio(
            'Coherence', 
            CCFR_VALUES, 
            index=0 if f'{model_name}_{doc_id}_coh_updated' not in st.session_state else CCFR_VALUES.index(st.session_state[f'{model_name}_{doc_id}_coh_updated']),
            key=f'{model_name}_{doc_id}_coh', 
            on_change=update_radio_coh,
            horizontal=True,
        )
        st.radio(
            'Consistency',
            CCFR_VALUES, 
            index=0 if f'{model_name}_{doc_id}_con_updated' not in st.session_state else CCFR_VALUES.index(st.session_state[f'{model_name}_{doc_id}_con_updated']),
            key=f'{model_name}_{doc_id}_con', 
            on_change=update_radio_con,
            horizontal=True,
        )
        st.radio(
            'Fluency', 
            CCFR_VALUES, 
            index=0 if f'{model_name}_{doc_id}_flu_updated' not in st.session_state else CCFR_VALUES.index(st.session_state[f'{model_name}_{doc_id}_flu_updated']),
            key=f'{model_name}_{doc_id}_flu', 
            on_change=update_radio_flu,
            horizontal=True,
        )
        st.radio(
            'Relevance', 
            CCFR_VALUES, 
            index=0 if f'{model_name}_{doc_id}_rel_updated' not in st.session_state else CCFR_VALUES.index(st.session_state[f'{model_name}_{doc_id}_rel_updated']),
            key=f'{model_name}_{doc_id}_rel', 
            on_change=update_radio_rel,
            horizontal=True,
        )

def _display_placeholder_model(
    model_name, 
    is_model_a,
    gen_samples, 
    doc_id, 
    bigbird_n_sent, 
    layout_bigbird_n_sent,
    prec_results_dir,
    rec_results_dir,
):
    if is_model_a:
        # st.subheader("Summary generated by BigBird")
        st.subheader("Summary generated by model A")
    else:
        # st.subheader("Summary generated by BigBird+Layout")
        st.subheader("Summary generated by model B")
    st.info("""
        Summary is split by sentence. 
        Click on any sentence to highlight the corresponding words in the ground-truth abstract. 
        Evaluate using per-sentence precision, recall, coherence, consistency, fluency, and relevance.
    """)
    
    def _update_gen_checkbox(sent_idx):
        for i in range(bigbird_n_sent):
            if model_name != "bigbird" or i != sent_idx:
                st.session_state[f"chk_bigbird_{doc_id}_{i}"] = False
        for i in range(layout_bigbird_n_sent):
            if model_name != "layout-bigbird" or i != sent_idx:
                st.session_state[f"chk_layout-bigbird_{doc_id}_{i}"] = False

    def _update_prec_eval(sent_idx):
        if f"{model_name}_{doc_id}_sent{sent_idx}_prec_updated" not in st.session_state:
            st.session_state[f'{model_name}_{doc_id}_sent{sent_idx}_prec_updated'] = st.session_state[f'{model_name}_{doc_id}_sent{sent_idx}_prec'] 
        st.session_state[f'{model_name}_{doc_id}_sent{sent_idx}_prec_updated'] = st.session_state[f'{model_name}_{doc_id}_sent{sent_idx}_prec'] 
        with open(os.path.join(prec_results_dir, f"{model_name}_{doc_id}_sent{sent_idx}_prec"), 'a') as fw:
            fw.write(str(st.session_state[f'{model_name}_{doc_id}_sent{sent_idx}_prec']) + "\n")


    for sent_idx, sent in enumerate(gen_samples[doc_id]):
        first_col, second_col, third_col = st.columns([1, 6, 7])
        with first_col:
            if sent_idx == 0:
                st.markdown("\n")
                st.markdown("\n")
            st.checkbox("", key=f'chk_{model_name}_{doc_id}_{sent_idx}', on_change=_update_gen_checkbox, args=(sent_idx,))
        with second_col:
            if sent_idx == 0:
                st.markdown("**Sentence**")
            st.markdown(sent)
        with third_col:
            st.radio(
                "Precision (%)", 
                PREC_VALUES, 
                key=f'{model_name}_{doc_id}_sent{sent_idx}_prec', 
                on_change=_update_prec_eval, 
                args=(sent_idx,),
                index=0 if f'{model_name}_{doc_id}_sent{sent_idx}_prec_updated' not in st.session_state else PREC_VALUES.index(st.session_state[f'{model_name}_{doc_id}_sent{sent_idx}_prec_updated']),
                label_visibility="visible" if sent_idx == 0 else "collapsed",
                horizontal=True,
            )

    def _update_rec_eval():
        if f"{model_name}_{doc_id}_rec_updated" not in st.session_state:
            st.session_state[f'{model_name}_{doc_id}_rec_updated'] = st.session_state[f'{model_name}_{doc_id}_rec'] 
        st.session_state[f'{model_name}_{doc_id}_rec_updated'] = st.session_state[f'{model_name}_{doc_id}_rec'] 
        with open(os.path.join(rec_results_dir, f"{model_name}_{doc_id}_rec"), 'a') as fw:
            fw.write(str(st.session_state[f'{model_name}_{doc_id}_rec']) + "\n")

    _, center, _ = st.columns([3, 8, 1])
    with center:
        st.radio(
            "Recall (%)",
            REC_VALUES,
            key=f'{model_name}_{doc_id}_rec',
            on_change=_update_rec_eval, 
            index=0 if f'{model_name}_{doc_id}_rec_updated' not in st.session_state else REC_VALUES.index(st.session_state[f'{model_name}_{doc_id}_rec_updated']),
            horizontal=True,
        ) 

def load_results_in_session_state(ccfr_results_dir, prec_results_dir, rec_results_dir, unable_to_eval_file):
    ccfr_results_files = os.listdir(ccfr_results_dir)
    prec_results_files = os.listdir(prec_results_dir)
    rec_results_files = os.listdir(rec_results_dir)

    for filename in ccfr_results_files:
        model_name, doc_id, cat = filename.split("_")
        with open(os.path.join(ccfr_results_dir, filename), 'r') as f:
            lines = f.readlines()
        last_result = int(lines[-1])
        st.session_state[f'{model_name}_{doc_id}_{cat}_updated'] = last_result

    for filename in prec_results_files:
        model_name, doc_id, sent_idx, _ = filename.split("_")
        with open(os.path.join(prec_results_dir, filename), 'r') as f:
            lines = f.readlines()
        last_result = int(lines[-1])
        st.session_state[f'{model_name}_{doc_id}_{sent_idx}_prec_updated'] = last_result

    for filename in rec_results_files:
        model_name, doc_id, _ = filename.split("_")
        with open(os.path.join(rec_results_dir, filename), 'r') as f:
            lines = f.readlines()
        last_result = int(lines[-1])
        st.session_state[f'{model_name}_{doc_id}_rec_updated'] = last_result

    if os.path.isfile(unable_to_eval_file):
        with open(unable_to_eval_file, 'r') as f:
            unable_to_eval_doc_ids = f.readlines()
        unable_to_eval_doc_ids = [doc_id.strip() for doc_id in unable_to_eval_doc_ids]
        for doc_id in unable_to_eval_doc_ids:
            st.session_state[f'unable_to_eval_{doc_id}_checked'] = True 


def loralay_eval_interface(
    gold_samples, 
    bigbird_samples, 
    layout_bigbird_samples, 
    doc_id, 
    all_doc_ids,
    samples_lang,
    ccfr_results_dir,
    prec_results_dir,
    rec_results_dir,
    unable_to_eval_file,
    models_A,
    samples_titles,
    samples_urls,
):
    st.title("LoRaLay Evaluation Interface")
    
    # Uncheck all radios
    st.markdown("""<style>div[role="radiogroup"] >  :first-child{
        display: none !important;
    }</style>""", unsafe_allow_html=True)


    load_results_in_session_state(ccfr_results_dir, prec_results_dir, rec_results_dir, unable_to_eval_file)

    last_idx = len(all_doc_ids) - 1

    if "doc_idx" not in st.session_state:
        st.session_state.doc_idx = all_doc_ids.index(doc_id)
    else:
        doc_id = all_doc_ids[st.session_state.doc_idx]
        with open("./last_doc_id.txt", 'w') as fw:
            fw.write(doc_id)

    if samples_lang[doc_id] == "en":
        stopwords = EN_STOPWORDS
    else:
        assert samples_lang[doc_id] == "fr"
        stopwords = FR_STOPWORDS

    st.header(f"Document {doc_id} ({st.session_state.doc_idx + 1}/{len(all_doc_ids)})")
    if doc_id in samples_titles:
        st.write(f"*{samples_titles[doc_id]}*")        
    if doc_id in samples_urls:
        st.write(f"[Link to PDF]({samples_urls[doc_id]})")

        
    placeholder_gold = st.empty()
    placeholder_A, placeholder_B = st.tabs(["Model A", "Model B"])

    with placeholder_gold.container():
        st.subheader("Ground-truth abstract")
        st.write(gold_samples[doc_id])

    bigbird_n_sent = len(bigbird_samples[doc_id])
    layout_bigbird_n_sent = len(layout_bigbird_samples[doc_id])

    if models_A[st.session_state.doc_idx] == "bigbird":
        model_A = "bigbird"
        model_A_samples = bigbird_samples
        model_A_n_sent = bigbird_n_sent
        model_B = "layout-bigbird"
        model_B_samples = layout_bigbird_samples
        model_B_n_sent = layout_bigbird_n_sent
    else:
        model_A = "layout-bigbird"
        model_A_samples = layout_bigbird_samples
        model_A_n_sent = layout_bigbird_n_sent
        model_B = "bigbird"
        model_B_samples = bigbird_samples
        model_B_n_sent = bigbird_n_sent

    with placeholder_A.container():
        _display_placeholder_model(
            model_A, 
            True,
            model_A_samples,
            doc_id, 
            bigbird_n_sent, 
            layout_bigbird_n_sent,
            prec_results_dir,
            rec_results_dir,
        )
        _create_radios(model_A, doc_id, ccfr_results_dir)

    for sent_idx in range(model_A_n_sent):
        if st.session_state[f'chk_{model_A}_{doc_id}_{sent_idx}']:
            annotated_gold_summ = _highlight_in_gold_sample(
                model_A_samples[doc_id][sent_idx],
                gold_samples[doc_id],
                stopwords
            )
            with placeholder_gold.container():
                st.subheader("Abstract")
                annotated_text(*annotated_gold_summ)
    

    with placeholder_B.container():
        _display_placeholder_model(
            model_B, 
            False,
            model_B_samples, 
            doc_id, 
            bigbird_n_sent, 
            layout_bigbird_n_sent,
            prec_results_dir,
            rec_results_dir
        )
        _create_radios(model_B, doc_id, ccfr_results_dir)

                
    for sent_idx in range(model_B_n_sent):
        if st.session_state[f'chk_{model_B}_{doc_id}_{sent_idx}']:
            annotated_gold_summ = _highlight_in_gold_sample(
                model_B_samples[doc_id][sent_idx],
                gold_samples[doc_id],
                stopwords
            )
            with placeholder_gold.container():
                st.subheader("Abstract")
                annotated_text(*annotated_gold_summ)

    def _update_unable_to_eval(doc_id):
        if os.path.isfile(unable_to_eval_file):
            with open(unable_to_eval_file, 'r') as f:
                unable_to_eval_doc_ids = f.readlines()
            unable_to_eval_doc_ids = [doc_id.strip() for doc_id in unable_to_eval_doc_ids]
        else:
            unable_to_eval_doc_ids = []

        if (
            f"unable_to_eval_{doc_id}_checked" not in st.session_state
            or not st.session_state[f"unable_to_eval_{doc_id}_checked"]
        ):
            st.session_state[f"unable_to_eval_{doc_id}_checked"] = True 
            unable_to_eval_doc_ids.append(doc_id)
        else:
            st.session_state[f"unable_to_eval_{doc_id}_checked"] = False
            assert doc_id in unable_to_eval_doc_ids
            unable_to_eval_doc_ids.remove(doc_id)

        with open(unable_to_eval_file, 'w') as fw:
            for doc_id in unable_to_eval_doc_ids:
                fw.write(doc_id + "\n")       
     

    st.checkbox(
        "I am unable to evaluate this document.", 
        value=True if f'unable_to_eval_{doc_id}_checked' in st.session_state and st.session_state[f'unable_to_eval_{doc_id}_checked'] else False,
        key=f'chk_unable_to_eval_{doc_id}', 
        on_change=_update_unable_to_eval, 
        args=(doc_id,)
    )

    def go_to_next():
        st.session_state.doc_idx += 1
    def go_to_previous():
        st.session_state.doc_idx -= 1

    left, _, right = st.columns([1, 8, 1])
    with left:
        if st.session_state.doc_idx > 0:
            st.button('Previous', on_click=go_to_previous)
    with right:
        if st.session_state.doc_idx < last_idx:
            next_is_disabled = False 
            for bigbird_sent_idx, layout_bigbird_sent_idx in zip(range(bigbird_n_sent), range(layout_bigbird_n_sent)):
                if f"bigbird_{doc_id}_sent{bigbird_sent_idx}_prec_updated" not in st.session_state:
                    next_is_disabled = True 
                    break
                if f"layout-bigbird_{doc_id}_sent{layout_bigbird_sent_idx}_prec_updated" not in st.session_state:
                    next_is_disabled = True 
                    break
            if f"bigbird_{doc_id}_rec_updated" not in st.session_state:
                next_is_disabled = True 
            if f"layout-bigbird_{doc_id}_rec_updated" not in st.session_state:
                next_is_disabled = True 
            for cat in ["coh", "con", "flu", "rel"]:
                if f"bigbird_{doc_id}_{cat}_updated" not in st.session_state:
                    next_is_disabled = True 
                    break
                if f"layout-bigbird_{doc_id}_{cat}_updated" not in st.session_state:
                    next_is_disabled = True 
                    break
            
            if f'unable_to_eval_{doc_id}_checked' in st.session_state and st.session_state[f'unable_to_eval_{doc_id}_checked']:
                next_is_disabled = False
            st.button('Next', on_click=go_to_next, disabled=next_is_disabled)

        

def load_samples(samples, is_gold=False):
    samples = [json.loads(sample) for sample in samples]
    if is_gold:
        samples_lang = {
            sample["id"]: sample["lang"] for sample in samples
        }
        # samples_titles = {
        #     sample["id"]: sample["title"] for sample in samples
        # }
        samples_titles = dict()
        samples_urls = dict()
        for sample in samples: 
            if "title" in sample:
                samples_titles[sample["id"]] = sample["title"]
            if "pdf_url" in sample:
                samples_urls[sample["id"]] = sample["pdf_url"]
    else:
        samples_lang = None
        samples_titles = None
        samples_urls = None 
    samples = {
        sample["id"]: sample["abstract"].strip() if is_gold else sent_tokenize(sample["output"].strip()) for sample in samples
    }
    return samples, (samples_lang, samples_titles, samples_urls)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    
    parser.add_argument(
        "--path_to_gold",
        type=str,
        default="samples/gold.txt",
    )
    parser.add_argument(
        "--path_to_bigbird",
        type=str,
        default="samples/bigbird.txt",
    )
    parser.add_argument(
        "--path_to_layout_bigbird",
        type=str,
        default="samples/layout-bigbird.txt",
    )
    parser.add_argument(
        "--path_to_models_A",
        type=str,
        default="samples/models_A.txt",
    )
    parser.add_argument(
        "--results_dir",
        type=str,
        default="eval_results",
    )
    parser.add_argument(
        "--overwrite_eval",
        action="store_true", 
    )
    args = parser.parse_args()

    with open(args.path_to_gold) as f:
        gold_samples = f.readlines()
    with open(args.path_to_bigbird) as f:
        bigbird_samples = f.readlines()
    with open(args.path_to_layout_bigbird) as f:
        layout_bigbird_samples = f.readlines()
    with open(args.path_to_models_A) as f:
        models_A = f.readlines()

    gold_samples, (samples_lang, samples_titles, samples_urls) = load_samples(gold_samples, is_gold=True)
    bigbird_samples, _ = load_samples(bigbird_samples)
    layout_bigbird_samples,  _ = load_samples(layout_bigbird_samples)
    models_A = [model.strip() for model in models_A]

    all_doc_ids = tuple([sample_id for sample_id, _ in gold_samples.items()])
    # all_doc_ids = sorted(all_doc_ids)

    ccfr_results_dir = os.path.join(args.results_dir, "ccfr_outputs")
    prec_results_dir = os.path.join(args.results_dir, "precision_outputs")
    rec_results_dir = os.path.join(args.results_dir, "recall_outputs")
    unable_to_eval_file = os.path.join(args.results_dir, "unable_to_eval.txt")

    @st.cache
    def prepare_results_dir():
        if os.path.isdir(args.results_dir):
            if args.overwrite_eval:
               
                if os.path.isdir(ccfr_results_dir):
                    shutil.rmtree(ccfr_results_dir)
                if os.path.isdir(prec_results_dir):
                    shutil.rmtree(prec_results_dir)
                if os.path.isdir(rec_results_dir):
                    shutil.rmtree(rec_results_dir)
                
                os.makedirs(ccfr_results_dir)
                os.makedirs(prec_results_dir)
                os.makedirs(rec_results_dir)
                if os.path.isfile("./last_doc_id.txt"):
                    os.remove("./last_doc_id.txt")
                if os.path.isfile(unable_to_eval_file):
                    os.remove(unable_to_eval_file)
            else:
                if not os.path.isdir(ccfr_results_dir):
                    os.makedirs(ccfr_results_dir)
                if not os.path.isdir(prec_results_dir):
                    os.makedirs(prec_results_dir)
                if not os.path.isdir(rec_results_dir):
                    os.makedirs(rec_results_dir)
        else:
            os.mkdir(args.results_dir)
            os.makedirs(ccfr_results_dir)
            os.makedirs(prec_results_dir)
            os.makedirs(rec_results_dir)
    
    prepare_results_dir()

    if os.path.isfile("./last_doc_id.txt"):
        with open("./last_doc_id.txt", 'r') as f:
            doc_id = f.read().strip()
    else:
        doc_id = all_doc_ids[0]

    loralay_eval_interface(
        gold_samples, 
        bigbird_samples, 
        layout_bigbird_samples, 
        doc_id, 
        all_doc_ids,
        samples_lang,
        ccfr_results_dir,
        prec_results_dir,
        rec_results_dir,
        unable_to_eval_file,
        models_A,
        samples_titles,
        samples_urls
    )
