{"id": "0806.3537", "output": "Conventional statistical learning theory attempts to bound the number of samples needed to learn to a specified level of accuracy for each of the above models (e.g. neural networks, support vector machines). However, if we allow ourselves to change the model, then the VC-dimension of the overall learning algorithm is not finite, and much of statistical learning theory does not directly apply. In contrast, we prove that distribution-independent bounds do not exist altogether for computable learning algorithms in our setting. Our results imply that computable learning algorithms in the universal setting must \"waste samples\" in the sense of requiring more samples than is necessary for statistical reasons alone.\n"}
{"id": "0808.2220", "output": "A real in the unit interval is computably enumerable if it is the limit of a computable, increasing sequence of rationals. We identify a real with its infinite binary expansion. A real is (algorithmic) random if its binary expansion is an algorithmic random (infinite) sequence. A machine is universal if it can simulate every machine. A real in the unit interval is computably enumerable if it is the limit of a computable, increasing sequence of rationals. We identify a real with its infinite binary expansion. A real is (algorithmic) random if its binary expansion is an algorithmic random (infinite) sequence. A machine is universal if it can simulate every machine. A real is computably enumerable if it is the limit of a computable, increasing sequence of rationals.\n"}
{"id": "0811.1250", "output": "This study proposes ABC-Boost (Adaptive Base Class Boost), a concrete implementation of ABC-Boost for multi-class classification. ABC-Boost is based on the following two key ideas: 1. For multi-class classification, popular loss functions for K classes usually assume a constraint such that only the values for K  1 classes are needed. Therefore, we can choose a base class and derive algorithms only for K  1 classes. 2. At each boosting step, although the base class is not explicitly trained, it will implicitly benefit from the training on K  1 classes, due to the constraint. Thus, we adaptively choose the base class which has the \"worst\" performance.\n"}
{"id": "0812.0197", "output": "We describe a new methodology for studying persistence of topological features across a family of spaces or point-cloud data sets. This theory of zigzag persistence generalises the successful and widely used theory of persistence and persistent homology. Moreover, zigzag persistence can handle several important situations that are not currently addressed by standard persistence. The novelty of our approach is that the direction of each linking map is arbitrary, in contrast to the usual theory of persistence where all maps point in the same direction.\n"}
{"id": "1203.4732", "output": "In this paper we introduce a new framework to characterize the expressive power of a query language. Our framework is based upon the notion of partitions of the domain, where each partition represents a level of undifferentiation among objects, values or vertices. We prove that the expressiveness of a query language can be stated as the conservation of some of those partitions, where the exact set of partitions that must be preserved depends on the data model. Subsequently, we show how to apply the new framework to analyze a simple graph-based model, hence proving that our characterization can be useful in comparing the expressive power of different data languages.\n"}
{"id": "1207.0783", "output": "In this paper, we propose a hybrid template update system for unimodal biometric systems. A user is represented by several biometric sub-references evolving in parallel by using different template update methods. A user is represented by several biometric sub-references evolving in parallel by using different template update methods. We propose two evaluation metrics in order to evaluate the efficiency of template update systems over several sessions. Experimental results show that the hybrid template update system performs better than the classic self-update system from the state of the art.\n"}
{"id": "1210.1932", "output": "We give a new presentation of multipersistence modules computable in polynomial time. Our algorithm has polinomial complexity for all multipersistence modules and in the one-critical case it essentially coincides with the algorithm presented in [4].\n"}
{"id": "1302.4020", "output": "The goal of this work is to explore the topological interference management problem with time-varying (alternating) connectivity. We consider the class of linear wired interference networks where the output at each receiver is a linear combination of the inputs from the transmitters. The topology information is only available to the transmitters through 1-bit feedback indicating whether an interference link is present or not, but no knowledge of channel coefficient value is available to the transmitter. We show that the sum capacity for the two-user interference network with alternating connectivity is 1+_D, where _D is the sum capacity of the network normalized by the capacity of a single link. We also show that the sum capacity for the two-user vector broadcast channel with alternating connectivity is 1+_D, where _D is the sum capacity of the network normalized by the capacity of a single link. We also show that the sum capacity for the two-user vector broadcast channel with alternating connectivity is equivalent to the two-user vector broadcast channel with alternating connectivity.\n"}
{"id": "1312.4231", "output": "In this paper, we construct a dependence space in the context of matroids and apply it to attribute reduction problems. First, a dependence space of matroids is proposed from the viewpoint of closure operator. Second, we study the dependence space by means of matroids. It is interesting to find that the set of consistent sets and the set of reducts of the dependence space are the family of independent sets and the family of bases of the corresponding matroid, respectively. Finally, matroids are studied by dependence spaces and two expressions for bases of matroids are presented.\n"}
{"id": "1512.00344", "output": "Interactions among individuals in a population can be described by networks of who-contacts of whom. In such networks the contact pattern is no longer static but evolves with the spread of an infectious disease according to the rules defining the rewiring process. Such a rewiring assumes transmission of information which allows people to gather knowledge about the disease status of their neighbours. Therefore, in such networks the contact pattern is no longer static but evolves with the spread of an infectious disease according to the rules defining the rewiring process. Pairwise models have been the main approach adopted for the analysis of epidemic dynamics on adaptive networks. This paper aims mainly at comparing the predictions from both modelling methodologies (pairwise/stochastic) for the initial phase of the Susceptible-Infectious-Recovered-Exposed-Infectious-Exposed (SEIR) network epidemics with preventive rewiring among individuals. In particular, we compute R_0 and the expected degree of infectives during the initial phase as a function of the rewiring rate. Both approximations lead to the same epidemic (or invasion) threshold in networks without rewiring. In fact, it is well known that both pairwise models and branching process approximations lead to the same epidemic (or invasion) threshold in networks without rewiring\n"}
{"id": "1604.06187", "output": "Evolutionary algorithms have been successfully used in the areas of music and art. The use of evolutionary algorithms for the generation of art has attracted strong research interest. The great majority of this work relates to using evolution to produce a final artistic product in the form of a picture, sculpture or animation. The focus of study in this paper is how evolutionary algorithms can be mirrored in image transitions. The transition process used in this work consists of evolving a given starting image S into a given target image T by random decisions. Considering an error function which assigns to a given current image X the number of pixels where it agrees with T and maximizes this function boils down to the classical OneMax problem for which numerous theoretical results on the runtime behaviour of evolutionary algorithms are available. We use the insights obtained in such studies and show how different processes have an influence on evolutionary image transition. Furthermore, we consider the effect of alternating different mutation operators over time. Our results show that the area of evolutionary image transition based on different well studied random processes provides a rich source of artistic possibilities with strong potential for further exploration.\n"}
{"id": "1604.08243", "output": "In this paper, we present a preliminary idea of deploying a lightweight micro cloud infrastructure in the sky using indigenously built low cost drones, single board computers and lightweight Operating System virtualization technologies such as unikernels/dockers. Our paper lays out the preliminary ideas on such a system that can be effectively deployed on demand.\n"}
{"id": "1605.06560", "output": "Deep Neural Networks (DNNs) have been widely used in diverse applications, ranging from computer vision to speech recognition, natural language processing, and domain adaptation. Compressing the model size becomes more important for applications on mobile and embedded devices. This paper proposes an approach to relieve this instability, still in a two-phase style for preserving efficiency. Specifically, we use multiple hash functions to map per virtual entry into multiple values in compression space. Then an additional network plays in a mapping function role from these hashed values to the virtual entry before hashing, which can be also regarded as \"reconstructing\" the virtual entry from its multiple hashed values. Plugged into and jointly trained within the original network, the reconstruction network is of a comparably ignorable size, i.e., at low memory cost. This functional hashing structure includes HashedNets as a degenerated special case, and facilitates less value collisions and better value reconstruction. Shortly denoted as FunHashNN, our approach could be further extended with dual space hashing and multi-hops. Experiments on several datasets demonstrate promisingly larger reduction of model sizes and/or less loss on prediction accuracy, compared with HashedNets.\n"}
{"id": "1607.01400", "output": "In this paper, we propose a clustering-based iterative algorithm to solve certain optimization problems in machine learning when data size is large. While it is standard practice to aggregate the data and calibrate the machine learning algorithm on aggregated data, we embed this into an iterative framework where initial aggregations are gradually disaggregated to the extent that even an optimal solution is obtainable. The focus of our work is to design a computationally tractable algorithm that actually yields an optimal solution in a finite number of iterations. In the computational experiment, we show that our algorithm outperforms the current state-of-the-art algorithms when the data size is large.\n"}
{"id": "1609.03234", "output": "Counterfactual Regret Minimization (CFR) is a popular iterative algorithm for imperfect-information extensive-form games. CFR minimizes regret independently at each decision point in the game. In this paper, we introduce a new form of RBP that we coin Total RBP. It alters the starting and ending conditions for pruning, and changes the way regrets are updated once pruning ends. A primary advantage of Total RBP is that in addition to faster convergence, it also reduces the space requirements of CFR over time. Specifically, after enough iterations are completed, space for certain pruned branches will never need to be allocated again. Space need not be reallocated for that branch until pruning ends and the branch cannot immediately be pruned again. In other words, all the data stored for a branch that is pruned can be discarded, and the space allocated to that branch can be freed.\n"}
{"id": "1703.07822", "output": "This paper proposes a data-efficient approach for learning mechanical models of objects using Bayesian optimization. The goal is to allow the robot to use predefined models of objects, in the form of prior distributions, and to improve the accuracy of these models on the fly by interacting with the objects. To solve the problem of modeling mechanical properties of objects, this paper proposes an online learning approach to identify mass and sliding models of objects using Bayesian optimization. The goal is to allow the robot to use predefined models of objects, in the form of prior distributions, and to improve the accuracy of these models on the fly by interacting with the objects. To solve the problem of modeling mechanical properties of objects, this paper proposes an online learning approach to identify mass and sliding models of objects using Bayesian optimization. The goal is to allow the robot to use predefined models of objects, in the form of prior distributions, and to improve the accuracy of these models on the fly by interacting with the objects.\n"}
{"id": "1008.2277", "output": "This paper deals with chain graphs under the Lauritzen-Wermuth-Frydenberg interpretation. We prove that the regular Gaussian distributions that factorize with respect to a chain graph G with d parameters have positive Lebesgue measure with respect to R_d, whereas those that factorize with respect to G but are not faithful to it have zero Lebesgue measure with respect to R_d. This means that, in the measure-theoretic sense described, almost all the regular Gaussian distributions that factorize with respect to G are faithful to it.\n"}
{"id": "1009.0558", "output": "This paper presents a sliding mode control method for two-level quantum systems to deal with bounded uncertainties in the system Hamiltonian. In particular, we propose two approaches of designing the measurement period for different situations which are dependent on the bound on the uncertainties and the allowed probability of failure. If the measurement period is small enough and the initial state is an eigenstate, the frequent measurements make the system collapse back to the initial state. This is related to the quantum Zeno effect.\n"}
{"id": "1206.1948", "output": "In this paper, we consider the discrete memoryless cognitive interference channel (DM-CIC). We first introduce the notion of less noisy DM-CIC and show that there are two different less noisy DM-CIC. In the former, the primary receiver is less noisy than the secondary receiver, whereas it is the opposite in the latter. Then, we propose two inner bounds for the DM-CIC; one based on superposition coding, and another one using independent coding. Obviously, these inner bounds are also valid for less noisy DM-CIC; in fact, one of these inner bounds is more suitable for the primary-less-noisy DM-CIC whereas the other one is better for the cognitive-less-noisy DM-CIC. Finally, we show that for the cognitive-less-noisy DM-CIC the inner and outer bounds coincide, and therefore we establish the capacity region for this class of DM-CIC.\n"}
{"id": "1505.06450", "output": "In this paper, the effect of aging and screening effect on network growth has been considered. A fractional order Barabsi-Albert (BA) model for network growth has been generalized to include the effect of history on the growth process. By using fractional calculus operators, the governing equation is a non-integer order differential equation. In this approach, the time distances are no longer identical. Hence, operators from fractional calculus appear. By working in fractional realm, the time distances are no longer identical. In fact in the growth process, some nodes can face long time delays before jumping to the next time step. At the same time some other nodes experience very short waiting period and pass more time steps relative to the frozen ones. As a node gets older, its probability to attain more links from new members decreases. Existing hubs will decay eventually and new hubs can emerge.\n"}
{"id": "1606.00541", "output": "In this paper, we introduce our work on speeding triangular solvers. A new matrix format, HEC (Hybrid ELL and CSR), is developed. A HEC matrix contains two matrices, an ELL matrix and a CSR (Compressed Sparse Row) matrix. The ELL part is in column-major order and is designed the way to increase the effective bandwidth. Based on these modified algorithms, ILU(k), ILUT and domain decomposition (Restricted Additive Schwarz) preconditioners are developed. Numerical experiments are performed on our workstation with Intel Xeon X5705 CPUs and NVIDIA Tesla C2050/C2070 GPUs. These experiments show that we can speed linear solvers around ten times faster.\n"}
{"id": "1611.03006", "output": "Genetic Relatedness Test (GRT) is a popular test offered by many direct-to-consumer (DTC) companies, namely, Ancestry.com, 23andme.com, and others. GRT is used to identify whether or not a pair of individuals are closely related, genetically speaking. The standard approach to relative identification is to detect the identity-by-descent (IBD) segments between the individuals, and further identify the degree of relatedness via the amount of shared IBD segments. However, collected genetic data is often impossible to anonymize and hard to protect from intentional or accidental leakage. In this paper, we focus on a popular test offered by many DTC companies, namely, Genetic Relatedness Test (GRT). This is used to identify whether or not a pair of individuals are closely related, genetically speaking. The standard approach to relative identification is to detect the identity-by-descent (IBD) segments between the individuals, and further identify the degree of relatedness via the amount of shared IBD segments. However, collected genetic data is often impossible to anonymize and hard to protect from intentional or accidental leakage. In this paper, we focus on a popular test offered by many DTC companies, namely, Genetic\n"}
{"id": "1105.3427", "output": "This paper deals with the efficient calculation of approximate solutions to a sequence of problems of the form P() where the parameter  belongs to a given set, which, for most applications, doesn't change significantly in two successive measurements. The real-time sequential convex programming (RTSCP) method proposed in this paper combines the RTI technique and the SCP algorithm: instead of solving with SCP every P() to full accuracy, RTSCP solves only one convex approximation P() to full accuracy, which is the approximate solution of P() calculated at the previous iteration. Therefore, RTSCP solves a sequence of convex problems corresponding to the different problems P(). As a byproduct of this result, we obtain a new proof of local convergence for the SCP algorithm.\n"}
{"id": "1206.6177", "output": "In this paper, we consider the structural analysis of dynamic lumped process models for high-index differential-algebraic equations (DAEs). In particular, we consider Pryce's method and the symbolic differential elimination package rifsimp. The key idea is taken from Pryce's signature-method. This is a powerful way to determine the index of the system, its number of degrees of freedom, and exactly which components should be given initial values. The nice feature of the work is a simple and straightforward method for analysing the structure of a differential algebraic system.\n"}
{"id": "1605.08838", "output": "We consider the dueling bandits problem, in which we are faced with a collection of arms, and pull a pair of arms while observing noisy binary feedback indicating which arm is best for each pulled pair. We consider utility-based weak regret, in the total order setting, when the total order is induced by a utility which is in turn a function of observable arm features, an unknown latent preference vector, and a known utility function. We provide an algorithm, Comparing The Best (CTB), that has expected cumulative utility-based weak regret that is constant in T, and that leverages the dependence between preferences over arms induced by the arm features and utility function to provide excellent empirical performance when prior information is available. While our regret bound's dependence on N is looser than Chen and Frazier (2017), our algorithm is more flexible in its ability to problem structure induced by the feature vectors, and outperforms it empirically by a substantial margin when N is small enough to allow computation that fully takes advantage of this problem structure.\n"}
{"id": "3298748", "output": "L'objectif de ce travail est de développer des méthodes d'apprentissage profond pour l'analyse et l'interprétation automatique des émotions à partir des mouvements du corps humain. Notre objectif est donc d'utiliser les données du jeu de données BOLD et d'extraire certaines caractéristiques géométriques de la posture, telles que les angles entre les articulations du corps, comme données d'entrée pour un réseau de type LSTM (\"Long Short Term Memory\").\n"}
{"id": "3298747", "output": "Les fraudes bancaires ont aujourd'hui un impact financier important et nécessitent d'être détectées au plus vite. Ces difficultés s'accompagnent de complexités additionnelles dues au caractère temporel et très déséquilibré des données ainsi qu'à l'évolution constante de patterns ou motifs de fraudes. De plus, dans ce domaine particulier non seule-ment les décisions doivent pouvoir être expliquées, mais le modèle derrière la prise de décision doit être compréhensible. Les modèles d'apprentissage dits \"black boxes\" même expliqués à posteriori, ne peuvent donc être envisagés. C'est pourquoi, l'utilisation d'un langage symbolique, via un apprentissage supervisé de règles de décision est priégiée. L'objectif de ce projet est d'induire un ensemble de règles métier dites business rules, à partir de données labellisées (exemple partiel de données inspiré de Synthetic Financial Datasets For Fraud Detection [1] (SFD) et de modèles de machine learning. Ceci permet d'avancer dans la détection et prédiction de fraudes dans le contexte challenging de la finance et du monde\n"}
{"id": "3282727", "output": "Les systèmes de calculs hautes performances ont vu leur complexité exploser avec la croissance des piles logicielles, les variabilités des processeurs ou l'évolution dynamique de la charge réseau ou mémoire. Cette complexité amène des variations de leur comportement, et notamment en performances. Ainsi, il est de plus en plus difficile de prédire précisément leur évolution. Par exemple, les variations des temps de lecture/écriture de fichiers dans une grille de calcul, et donc de la charge du serveur de fichiers, entraînent des variations des temps d'exécution des tâches soumises par les utilisateurs. Ce type de variations apparaît également dans le contexte de l'intergiciel CiGri. Son but est d'utiliser les ressources libres d'un ensemble de grappes de calculs (ou clusters), en y injectant des tâches de priorité minimale (ou best-effort). Ces dernières proviennent d'applications dites Bag-of-Tasks, constituées d'un grand nombre de tâches indépendantes, donc propices à leur parallélisation. Un des problèmes est lié à la potentielle surcharge du serveur héberg\n"}
{"id": "3317641", "output": "Les simulations sont souvent utilisées pour étudier des systèmes complexes comme les écosystèmes, le trafic routier, la gestion de crises... Ils sont constitués d'un grand nombre d'entités dont le comportement ainsi que leurs interactions décrivent la trajectoire du système. Bien que nous soyons en présence de systèmes naturellement distribués du fait de leur nature hétérogène organisée, ce type de problème ne permet de placement statique à cause des aspects dynamiques. En effet des organisations se font et se défont en cours de simulation. Une façon donc de distribuer de telles applications est de détecter les organisations en cours de simulation afin de minimiser en particulier les coûts de communication dans le respect d'un bon équilibrage de charge. Cela revient donc à du clustering dynamique (organisations) sous contraintes (équilibrage). Une fois les clusters détectés les entités sont rapprochées par migration. Ces changements permanents dès qu'ils apparaissent. Ces changements sont l'une des principales motivations dans l'utilisation d'un algorithme fourmi\n"}
{"id": "3292923", "output": "L'analyse de l'apprentissage (Learning Analytics ou LA) qui permet de comprendre le parcours d'un apprenant s'est considérablement développée ces dernières années. Consacrée à l'analyse des données de formation, elle vise à exploiter le potentiel des quantités de plus en plus importantes de données décrivant les informations personnelles, les données d'interaction et les données académiques générées par l'utilisation des environnements d'apprentissage en ligne (EAL). Cependant, la diversité des EAL existants complique la tâche d'analyse des données d'apprentissage, cette situation est encore amplifiée par la nécessité de combiner des données provenant de diverses sources. Notre étude s'inscrit dans ce contexte, elle ré-pond aux questions suivantes : sur quelle base peut-on concevoir un outil d'analyse capable de favoriser l'engagement et de prédire la réussite des apprenants en ligne? Comment rendre l'outil d'analyse interopérable? En effet, nous proposons dans ce travail un outil de communication visuelle interopérable, conçu sous forme de tableaux de bord pour les enseignants et les apprenant\n"}
{"id": "3292753", "output": "La fluence en lecture est couramment évaluée en mesurant le nombre de mots correctement lus par minute (NMCLM). Cependant, cette méthode se concentre sur la mesure du décodage et de la vitesse uniquement, au détriment de la prosodie, expressivité et phrasé. Cette mesure restrictive entretient ainsi la confusion entre lecteur rapide et bon lecteur, créant des lecteurs rapides mais qui ne comprennent pas forcément le texte lu. Cette prévalence du NMCLM dans l'évaluation de la fluence est en partie due à la difficulté d'évaluation des dimensions prosodiques, notamment leurs conséquences sur le phrasé et l'expressivité des lectures. En effet, s'il est aisé d'évaluer la justesse de la prononciation des mots, il y a de nombreuses façons licites de lire un texte avec expressivité. La prosodie est pourtant une compétence dont l'importance dans l'acquisition de la lecture est de plus en plus reconnue. Pourtant le développement de la prosodie en lecture a été assez peu étudié. Les études, menées essentiellement en anglais et en\n"}
{"id": "3313637", "output": "La tonique, la tierce et la quinte de l'accord correspondent au 1 er, 3 ème et 5 ème degré de la gamme modale. Dans ce cas on ne peut pas construire l'accord de Fa mineur par superposition de notes alternées. Dans certaines conditions que l'on verra par la suite, on peut construire un accord par superposition de notes al- ternées d'une gamme. Dans ce cas la tonique, la tierce et la quinte de l'accord correspondent à la 1 ère, la 3 ème et la 5 ème note de la gamme modale correspondante. Par un simple calcul informatique on peut vérifier que si on considère les gammes à 6 ou 8 notes qui n'ont pas de demi-tons successifs [1] cette condition n'est jamais satisfaite. L'exemple suivant montre cette correspondance, dans le cas où on construit l'accord de Ré mineur à partir de la gamme de do majeur : A titre d'exemple il s'agit de l'enchainement des notes {ré, fa, la}.\n"}
{"id": "3313639", "output": "En mathématiques, le problème de la séparation des éléments d'un ensemble fini dans une séquence u 1... u N est de telle sorte que les distances d(u i, u j) sont petites si et seulement si |i − j| sont aussi petites [12]. Le domaine de recherche de toutes les séquences possibles est trop large pour être explorée manuellement. En effet, le nombre de possibles arrangements de U est égale à N  N × (N − 1) ×.... Ce nombre est over one million pour N  10 et over one billion pour N  13. L'exploration manuelle de telles séquences nécessite donc l'aide de l'ordinateur. Dans cet article, nous décrivons le travail algorithmique qui a conduit à la synthèse de Synopsis Seriation. Sur un niveau conceptuel, le brouillage implique un agent virtuel qui \"écoute\" à l'Input de Synopsis, segmente ses segments en segments temporels, et finalement re-arrange ces segments pour maximiser la similarité auditive entre\n"}
{"id": "3313612", "output": "L'une des activités encadrées par le projet « Organisations musicales symbiotiques : une révision de la notion de concert de recherche-création faisant appel à l'informatique musicale » a lieu à la MSH PN. Son objectif est de revisiter la pratique actuelle musicale notamment par le biais de la musique en réseau. L'une des activités encadrées par ce projet consiste à réaliser des séances de live patching avec un groupe Marcello Messina UFPB – Federal University of Paraiba, Brésil d'élève du Conservatoire. Cette pratique a été choisie, car nous organisons depuis 2018 des séances de patching collaboratif, spécialement en rapport avec le développement du logiciel Kiwi. De cette démarche, a découlé notre recherche de post-doctorat « Live patching para com kiwi e Faust: uma proposição artística e pedagógica » à l'Université Fédéral da Paraíba, à João Pessoa (Brésil). Cette recherche est menée en collaboration avec le projet « Live/Acc/Patch » basé en deux universités brésiliennes, Université Fédéral\n"}
{"id": "3320332", "output": "Dans cet article, nous abordons la tâche de la reconnaissance d'entités nommées (NER) qui vise à identifier des entités du monde réel, telles que les noms de personnes, d'organisations et de lieux à partir des textes bruts. La majorité de ces documents est numérisée et traitée par un outil de reconnaissance optique de caractères (OCR) pour transcrire le texte. Cela conduit à des erreurs dans le texte transcrit, notamment des emplacements ou des noms de personnes mal orthographiés, ce qui est problématique puisque ce type d'entité nommée fait fréquemment partie des requêtes soumises aux collections patrimoniales. Pour relever ces défis nous proposons un modèle NER robuste basé sur une pile de Transformers qui comprend des encodeurs BERT affinés. Nous étudions l'impact d'un tel modèle, et nous concluons que ce type de modèle est adapté à l'extraction d'entités à partir de documents histo-riques.\n"}
{"id": "3329514", "output": "Dans cet article, nous montrons comment utiliser à la fois l'alignement à la demande des phrases parallèles et l'estimation à la volée des modèles de traduction permet d'obtenir une réduction massive (jusqu'à 93% dans nos expériences) en temps de développement par rapport à un système de référence à l'état de l'art, tout en offrant un avantage en termes de qualité de traduction sous certaines configurations. Nous montrons en particulier que l'absence d'un ensemble d'expériences peut être compensée en utilisant immédiatement des documents traduits.\n"}
{"id": "3321348", "output": "L'objectif de cette étude est de caractériser l'efficacité de la dynamique attentionnelle guidée par une politique cérébrale intrinsèque de l'attention sélective par le biais de mesures d'activité EEG lors d'une tâche expérimentale contrôlée contrôlée de changement attentionnel inter-modal. Plus précisément, nous supposons que la dynamique d'états (réseaux fonction-nels d'attention) est régie par une politique optimisant l'utilisation des chaînes de Markov dites contrôlées. Cette approche permet d'obtenir une modélisation dynamique en considérant que chaque réseau fonctionnel représente un état d'un système. Plus récemment, cette approche à été étendue à l'utilisation de Chaînes de Markov pour modéliser la dynamique de ce système.\n"}
{"id": "3297018", "output": "L'Institut Français de Bioinformatique (IFB) propose différents services pour le traitement des données des sciences de la vie. Ces services s'appuient sur une infrastructure distribuée entre les plateformes régionales membres de l'IFB proposant deux types d'environnements de calculs et traitements, suivant un modèle de cluster ou celui de cloud computing. Une partie de l'offre de services de l'IFB est ainsi basée sur une fédération de clouds académiques (détails en ligne). Cette infrastructure IFB-Biosphère est distribuée entre les plates-formes participantes sous la forme d'une fédération de clouds, fournissant des services standards et personnalisables.\n"}
{"id": "3339652", "output": "Cet article s'intéresse à l'utilisation d'une caméra omnidirectionnelle pour l'Asservissement Visuel Virtuel Direct. Il considère l'alignement 3D d'images omnidirectionnelles comme des propriétés directes. Les contributions concernent une adaptation de l'optimisation de la pose aux caméras omnidirectionnelles et une révision des règles d'initialisation et d'optimisation de l'étendue de l'alignement 3D de la caméra. Ces améliorations conduisent à une diminution de la largeur de l'angle de convergence de la caméra, telle que démontrée par les évaluations. Appliquée à des images acquises sur un robot mobile au sein d'un environnement urbain, l'utilisation d'un cloud 3D coloré montre une grande robustesse au mouvement inter-caméra, par rapport aux approches utilisant uniquement des pixels.\n"}
{"id": "3339664", "output": "La tâche de segmentation d'instance a été explorée principalement avec des images rectilinéaires. Mais dans les images fisheye, cette tâche n'a pas encore été complètement explorée. Un modèle de CNN qui peut performer bien dans le domaine rectilinéaire ou fisheye sans modifications spécifiques a des avantages en termes de puissance de calcul, de paramètres importants pour des applications réelles, par exemple, dans les environnements de transports. Dans ce papier, nous montrons qu'une augmentation de données sur des images fisheye peut améliorer les performances de segmentation d'instance tout en conservant des performances rectilinéaires.\n"}
{"id": "3339687", "output": "La détection et le suivi d'objets multiples restent un grand défi dans le domaine de la vision par ordinateur. Cette tâche est encore plus complexe lorsqu'il s'agit de suivre des troupeaux de chèvres dans des enclos. En effet, les chèvres étant très similaires, il est difficile de trouver des caractéris-tiques pour les séparer efficacement par rapport à un suivi de personne où on pourrait utiliser des caractéristiques de couleur par exemple. La grande densité des chèvres dans les enclos augmente les cas d'occultations et peut entraîner des échecs de détection. La construction de bases d'entraînement et de test est également très couteuse par manque de bases vidéos existantes dans ce contexte. Le travail présenté dans cet article porte sur la détection et le suivi des animaux en situation d'élevage. Nous avons étudié une variété de méthodes et de technologies à base de caméras vidéo pour détecter et suivre les animaux en situation d'élevage. En utilisant l'imagerie couleur tradi- tionnelle et la soustraction d'arrière-\n"}
{"id": "3339670", "output": "Les troubles des vaisseaux sanguins hépatiques résultent généralement d'un flux sanguin insuffisant venant ou sortant du foie, induit par la cirrhose et d'autres pathogènes hépatiques (carcinome hépatocellulaire par exemple). Pour aider les experts dans leurs diagnostics et la planification des traitements liés à ces maladies, une méthode précise de segmentation des vaisseaux est néces-saire en pratique clinique, quelles que soient les modalités d'images utilisées comme la TDM (Tomodensitométrie) ou l'IRM (Imagerie par Résonance Magnétique) par exemple. Avec l'arrivée du Deep Learning (DL) ces dernières années, des méthodes de segmentation des vaisseaux ont été développées avec des réseaux DL sur différentes modalités d'imagerie. L'article [19] a proposé une méthode DL basée sur une prédiction préliminaire des vaisseaux hépatiques en utilisant des patchs d'entraînement extraits des trois plans : sagittal, coronaire et transversal, issues d'images IRM. Les auteurs\n"}
{"id": "3292785", "output": "Les structures académiques modifient leurs pratiques d'enseignement afin d'ex-ploiter les nouvelles technologies et les avancées dans le domaine des EIAH, et plus généralement pour répondre aux besoins de la société. Ainsi, il est primordial d'étudier ces changements pour mieux les comprendre et assister correctement les acteurs pédagogiques (e.g. étudiants, enseignants, institutionnels). Une transformation majeure de ces institutions est le remplacement progressif de cursus pré-définis en faveur d'un modulaires. Dans ce paradigme, un étudiant doit choisir une certaine quantité de cours chaque semestre pour construire son propre parcours, lui donnant la liberté d'être en accord avec ses attentes (e.g. objectifs professionnels). Cela introduit de nombreuses probléma- tiques pour tous les acteurs pédagogiques. En effet, l'accroissement du volume des étudiants, combiné aux nouvelles structurations des enseignements, re- quiert d'apporter des outils automatisés afin d'aider les acteurs académiques à proposer un support personnalisé et adapté aux étudiants. Du point de vue des étudiants, la personnalisation du cursus nécessite une capacité de\n"}
{"id": "3339624", "output": "La segmentation des vaisseaux sanguins est une tâche difficile car ils sont fins, connectés et tortueux. Des approches d'apprentissage profond ont été développées pour traiter cette problématique, mais elles nécessitent une large base de données annotée pour chaque nouvelle application d'intérêt, qui est très difficile à construire pour les réseaux vasculaires. Dans ce travail, plutôt que d'apprendre la tâche de segmentation, nous proposons d'apprendre un terme de régularisation reconnecteur. Ce terme généralise mieux les modèles de segmentation appris, et peut être facilement injecté dans un schéma d'optimisation variationnel.\n"}
{"id": "3290040", "output": "Le méta-design est une méthode de conception participative avancée, dans laquelle les utilisateurs finaux (« owners of prob-lems ») sont impliqués de façon centrale dans les phases initiales de conception. Mais, ils doivent aussi avoir les moyens de continuer à être concepteurs durant les phases d'utilisation des artefacts, grâce à l'underdesign que Fischer et al. [3] définissent comme : « [.. ] underdesign aims to provide social and technical instruments for owners of problems to create the solutions [of their prob-lems] themselves at use time. » Nos travaux visent à s'interroger sur cette approche dans le contexte de l'utilisation des jeux sérieux par les enseignants en tant que owners of problems. Plus précisément, les travaux présentés ici rapportent l'amorçage d'un projet dans lequel nous nous intéressons à l'enseignement de la pensée informatique, et à l'étude de la mise en place d'une démarche de méta-design avec des jeux sérieux. L'objectif du projet est d'exploiter un jeu sérieux existant et d'étudier dans quelle mesure il est possible de le rendre «\n"}
{"id": "3290068", "output": "L'analytique des apprentissages avec le numérique (traduction française de Learn Analytics) est un domaine scientifique récent lié aux apprentissages éducatifs dont la première conférence internationale scientifique, a eu lieu en 2011. Parfois, les connaissances produites dans un cadre scientifique entrent en conflit avec les croyances et habitudes antérieures de la société. Avec le temps et les nouveautés produites par le terrain, différents acteurs ou groupes sociaux forment une compréhension commune - une représentation -, de ce qu'est le domaine d'étude, de ce qu'il produit, de la façon dont il pourrait être utile ou néfaste, etc. Le processus d'internalisation (sociale) de nouvelles informations (sci-entifiques) a fait l'objet d'études dans de nombreux domaines par chercheurs in-essés par la théorie des Représentations Sociales (RS). Par conséquent, lorsque l'on tente de mettre en œuvre les résultats des LA dans un cadre éducatif, il est important de comprendre à l'avance la nature de ces représentations. Nos recherches sont : 1/ Quelle est la représentation sociale des LA parmi les parties prenantes?\n"}
{"id": "3339685", "output": "Dans cet article, nous présentons trois méthodes de l'état de l'art dans l'extraction des endmembers. Ces méthodes ont été initialement utilisées dans le domaine de la télédétection. Elles sont appliquées à un nouveau domaine : les peintures. Nous comparons et analysons leurs performances et résultats.\n"}
{"id": "3298729", "output": "Les habitats intelligents ont vu croître leur intérêt ces dernières années. Initialement destinés à décrire les architectures et méthodes de constructions intelligentes, le périmètre du bâtiment intelligent s'est élargi à la suite des avancées dans les domaines de l'élec-tronique, des technologies de l'information et de la communication, des capteurs et actionneurs. L'accessibilité grandissante à internet, aux capteurs et actionneurs a permis la démocratisation de certains usages comme le pilotage centralisé des chauffages, des éclairages ou encore l'assistance à la personne. En parallèle, nous observons un vieillissement de nos populations. Nous nous intéressons plus particulièrement aux modélisations de comportements intra et inter utilisateurs ainsi qu'aux systèmes d'apprentissage par renforcement. Ces travaux se placent dans le domaine de l'Ambient Assisted Living et visent à proposer un nouveau système permettant au logement de s'adapter aux besoins de plusieurs utilisateurs. Pour ce faire, nous devons prendre en compte les retours implicites et explicites de ceux-ci\n"}
{"id": "3356549", "output": "L'Entomologie Médico-Légale exploite les indices entomologiques (i.e. les insectes nécrophages retrouvés sur ou à proximité de la victime) afin de déterminer l'intervalle post-moterm (IPM). Cette technique soulève un intérêt croissant dans les polices scientifiques du monde entier. Cependant, la diversité des modèles utilisés par les différents experts amène à s'interroger sur la fiabilité des résultats fournis. Il semble donc judicieux d'intégrer une approche de fusion afin de fournir un résultat global cohérent et objectif. Cet article présente une première solution à ce problème.\n"}
{"id": "3359983", "output": "Nous proposons une représentation de l'information en Recherche d'Information (RI) basée sur les sous-arbres. Cette représentation s'appuie sur des représentations sémantiques des sous-arbres et des ontologies.\n"}
